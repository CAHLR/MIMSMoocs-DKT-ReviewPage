{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "import os\n",
    "import json\n",
    "import tensorflow as tf\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'phase 1- delft 14'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# # \"\"\"phase 1- delft 15\"\"\"\n",
    "\n",
    "# data_dir=''\n",
    "# event_dict=('delft15_phase2/all_event_dict_delft15.json')\n",
    "# skill=os.path.join(data_dir+\"skill_df_delft_15.csv\")\n",
    "# response=os.path.join(data_dir+\"response_df_delft_15.csv\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\"\"\"phase 1- delft 14\"\"\"\n",
    "\n",
    "\n",
    "# data_dir='../code/data_dkt/delft14_phase1/'\n",
    "# skill_dict=json.load(open('data_dkt/delft15_phase2/skill_dict_delft_all_0_336_all.json'))\n",
    "# skill=os.path.join(data_dir+\"skill_df_delft_14_phase1.csv\")\n",
    "# response=os.path.join(data_dir+\"response_df_delft_14_phase1.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'phase 2 '"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\"\"\"phase 2 \"\"\"\n",
    "# data_dir = \"Delft15_phase2/\"\n",
    "# skill_dict=json.load(open(os.path.join(data_dir,\"unique_events.json\")))\n",
    "# response = os.path.join(data_dir,\"effort_response.csv\")\n",
    "# skill = os.path.join(data_dir,\"skill.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ls: cannot access '../code/data_dkt/delft15/': No such file or directory\r\n"
     ]
    }
   ],
   "source": [
    "\n",
    "!ls ../code/data_dkt/delft15/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Changed processing file data_helper.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    " \n",
    "\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "import os\n",
    "\n",
    " \n",
    "\"\"\" ONE HOT ENCODING OF SKILL AND RESPONSE DATA\"\"\"  \n",
    "\n",
    "\n",
    "def load_data(skill_csv,response_csv,skill_json,problem_num,is_behaviour=False):\n",
    "    \"\"\"\n",
    "    This function reads data files:\n",
    "    1. skill_dict:reads data from __skill_dict.json__ which maps skills to numbers 1,2..\n",
    "    2. skill_csv: reads data from __skill.csv__ which is a sequence of exercise or skills attempted by a student\n",
    "    3. response_csv: reads data from reponse.csv which is sequence of binary response to skill/exercise in skill.csv by each student\n",
    "    4. problem_num: total number of problem events in the course, each tagged from 1 to problem_num in skill_json which a dictionary that maps events to integers\n",
    "    5. is_behaviour is the boolean value which is TRUE when we want to include behavior events in our model or false for phase-1 dkt\n",
    "\n",
    "    \"\"\"\n",
    "    #response_df = pd.read_csv('correct.tsv', sep='\\t').drop('Unnamed: 0', axis=1)\n",
    "    # skill_df = pd.read_csv('skill.tsv', sep='\\t').drop('Unnamed: 0', axis=1)\n",
    "    # assistment_df = pd.read_csv('assistment_id.tsv', sep='\\t').drop('Unnamed: 0', axis=1)\n",
    "    # data_dir=\"data/dktData/\"\n",
    "    data_dir=\"\"\n",
    "    response_csv = os.path.join(data_dir,response_csv)\n",
    "    # response_df = pd.read_csv(response_csv, sep='\\t').drop('Unnamed: 0', axis=1)\n",
    "    response_df = pd.read_csv(response_csv)\n",
    "    skill_csv = os.path.join(data_dir,skill_csv)\n",
    "    skill_df=pd.read_csv(skill_csv)\n",
    "    skill_dict=json.load(open(skill_json))\n",
    "\n",
    "\n",
    "     \n",
    "#   1. skill matrix\n",
    "    skill_matrix = skill_df.iloc[:, 1:].values\n",
    "#   2. response matrix\n",
    "    response_array = response_df.iloc[:, 1:].values\n",
    "    print('skill_matrix .shape,response_array.shape')\n",
    "    print(skill_matrix .shape,response_array.shape)\n",
    "    if is_behaviour is False:\n",
    "        non_problem_event_num=0\n",
    "        skill_matrix[skill_matrix>problem_num]=0\n",
    "    else:\n",
    "        non_problem_event_num=len(skill_dict)-problem_num\n",
    "    return skill_matrix,response_array,problem_num, non_problem_event_num\n",
    "\n",
    "    \n",
    "def preprocess(skill_matrix,response_array,problem_num, non_problem_event_num):\n",
    "    \"\"\"\n",
    "    This function extracts the skills and responses from the loaded files excluding student ids\n",
    "    :param skill_df: skills attempted by a student at each timestep\n",
    "    :param response_df: responses on the exercises  by a student at each timestep\n",
    "    :param problem_num: Total number of problem events in the course\n",
    "    :param non_problem_num: Total number of non-problem events \n",
    "    \"\"\"\n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "#   1. skillarray\n",
    "    skill_array =convert_event_to_one_hot(skill_matrix, problem_num+non_problem_event_num)\n",
    "      \n",
    "#  2. skill_response array\n",
    "    skill_response_array = append_response_one_hot(skill_array,skill_matrix, response_array,problem_num)\n",
    "    \n",
    "    print('skill_array.shape,response_array.shape,skill_response_array.shape')\n",
    "    print(skill_array.shape,response_array.shape,skill_response_array.shape)\n",
    "    \n",
    "    return skill_array, response_array, skill_response_array\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def convert_event_to_one_hot(skill_matrix, vocab_size):\n",
    "    # 1. Create one hot encode row for each integer from 0 to vocab_size\n",
    "    print(vocab_size)\n",
    "    one_hot_dict = np.eye(vocab_size) \n",
    "    # 2. TO ASSIGN [000] to all out of vocab_size numbers, add last row with all zeros\n",
    "    one_hot_dict = np.vstack((one_hot_dict,np.zeros(vocab_size)))\n",
    "#     ADDED ONE MORE ROW SO THAT  IF WE FILL NA WITH -1 then -1-1= -2 ,\n",
    "# so 2nd last row becomes the assigned value\n",
    "    one_hot_dict = np.vstack((one_hot_dict,np.zeros(vocab_size)))\n",
    "    \n",
    "    \n",
    "    # sequence length is the number timesteps in the sequence\n",
    "    sequence_len = skill_matrix.shape[1] \n",
    "    # instantiation of a numpy array with all elements 0\n",
    "    on_hot_sequence = np.empty((skill_matrix.shape[0],sequence_len, vocab_size))\n",
    "\n",
    "    for row in range(skill_matrix.shape[0]):\n",
    "        # set vocabulary values in skills sequence of a student equal to 1, index of skills starts at 1\n",
    "        on_hot_sequence[row] = one_hot_dict [skill_matrix[row]-1] #grab 1-hot rows for integers in skill_matrix\n",
    "    print('Check encode in skill and one hot skill:', len(skill_matrix[skill_matrix!=0]),np.sum( on_hot_sequence))\n",
    "    return on_hot_sequence\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def append_response_one_hot(skill_array,skill_matrix, response_matrix, problem_num):\n",
    "    \"\"\"\n",
    "   params:\n",
    "       skill_matrix: 2-D matrix (student, skills)\n",
    "       response_matrix:  2-D matrix (student, responses)\n",
    "    with_response_vocab_size: Number of (2*problem events AND non-problem events) in the course\n",
    "   returns:\n",
    "       a 3d-darray with a shape like (student, sequence_len,problem_num)\n",
    "   \"\"\"\n",
    "    # 1. Create one hot encode row for each integer from 0 to problem_num\n",
    "    one_hot_dict_problems_only = np.eye(problem_num) \n",
    "    # 2. TO ASSIGN [000] to all out of vocab_size numbers\n",
    "    one_hot_dict_problems_only= np.vstack((one_hot_dict_problems_only,np.zeros(problem_num)))\n",
    "    #     ADDED ONE MORE ROW SO THAT  IF WE FILL NA WITH -1 then -1-1= -2 ,\n",
    "# so 2nd last row becomes the assigned value\n",
    "    one_hot_dict_problems_only= np.vstack((one_hot_dict_problems_only,np.zeros(problem_num))) \n",
    "    # 3. Get problem  ids of problems that are correct so that they can be assigned 1 value in one hot encode\n",
    "#     all other  are 0, - ----this is why we encode are not encoding  any skill as  ----\n",
    "    skill_matrix_only_correct_problems=skill_matrix*response_matrix\n",
    "\n",
    "  \n",
    "    # sequence length is the number timesteps in the sequence\n",
    "    sequence_len = skill_matrix.shape[1] \n",
    "    # instantiation of a numpy array with all elements 0\n",
    "    response_one_hot = np.empty((skill_matrix.shape[0],sequence_len, problem_num))\n",
    "    # iterate over each student in data\n",
    "    for i in range(response_matrix.shape[0]):\n",
    "        # set vocabulary values in skills attempted by a student equal to 1\n",
    "        # get encodes for sequences with non-zero problem\n",
    "        response_one_hot[i]=one_hot_dict_problems_only[skill_matrix_only_correct_problems[i]-1]\n",
    "        \n",
    "    print('Check number correct in response and one hot response:', np.sum(response_matrix),np.sum(response_one_hot))\n",
    "    skill_response_array=np.concatenate((skill_array,response_one_hot),axis=2)\n",
    "    print('skill_array.shape,response_one_hot.shape,skill_response_array.shape')\n",
    "    print(skill_array.shape,response_one_hot.shape,skill_response_array.shape)\n",
    "    return  skill_response_array\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DKT.PY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Model\n",
    "from keras.layers import Input, Dropout, Masking, Dense, Embedding\n",
    "from keras.layers import Embedding\n",
    "from keras.layers.core import Flatten, Reshape\n",
    "from keras.layers import LSTM\n",
    "from keras.layers import merge\n",
    "from keras.layers.merge import multiply\n",
    "from keras.callbacks import EarlyStopping\n",
    "from keras import backend as K\n",
    "from theano import tensor as T\n",
    "from theano import config\n",
    "from theano import printing\n",
    "from theano import function\n",
    "from keras.layers import Lambda\n",
    "import theano\n",
    "import numpy as np\n",
    "import pdb\n",
    "from math import sqrt\n",
    "from keras.callbacks import Callback\n",
    "\n",
    "\n",
    "\n",
    "class DKTcustomloss():\n",
    "\n",
    "    def __init__(self, \n",
    "                input_dim, \n",
    "                input_dim_order, \n",
    "                hidden_layer_size, \n",
    "                batch_size, \n",
    "                epochs,\n",
    "                x_train=[], \n",
    "                y_train=[], \n",
    "                y_train_order=[],\n",
    "                validation_split=0.0,\n",
    "                validation_data=None,\n",
    "                optimizer='adam',\n",
    "                callbacks=None):\n",
    "        \"\"\"\n",
    "\n",
    "        :param input_dim: dimension of the input at one timestamp (dimension of x_t= 2*num_skills)\n",
    "        :param input_dim_order: dimension of the one-hot representation of problem to check order of occurence(=num_skills)\n",
    "        :param hidden_layer_size: number of nodes in hidden layer\n",
    "        :param x_train: 3D matrix of size (samples, number of timestamp/sequence length, dimension of input vec (x_t) )\n",
    "        :param y_train: a matrix of responses (samples,number of timestamp/sequence length)\n",
    "        :param y_train_order: shape of output equal to number of timesteps\n",
    "        :param validation_split:\n",
    "        :param validation_data:\n",
    "        :param optimizer:\n",
    "        :param callbacks:\n",
    "\n",
    "        \"\"\"\n",
    "        ## input dim is the dimension of the input at one timestamp (dimension of x_t)\n",
    "        self.input_dim = int(input_dim) #2* num_skills\n",
    "\n",
    "        ## input_dim_order is the dimension of the one-hot representation of problem\n",
    "        ## CHECK: order of occurence of responses should be according to timestamp\n",
    "        self.input_dim_order = int(input_dim_order)#num_skills\n",
    "\n",
    "        self.hidden_layer_size = int(hidden_layer_size)\n",
    "        self.batch_size = int(batch_size)\n",
    "        self.epochs = int(epochs)\n",
    "\n",
    "        ## x_train is a 3D matrix of size (samples, number of timestamp, dimension of input vec (x_t) )\n",
    "        ## in cognitive tutor # of students * # total responses * # input_dim\n",
    "        self.x_train = x_train\n",
    "        ## y_train is a matrix of (samples one hot representation according to problem output value at each timestamp (y_t) )\n",
    "        self.y_train = y_train\n",
    "        ## y_train_order is the one hot representation of problem according to timestamp starting from\n",
    "        ## t=1 if training starts at t=0\n",
    "        self.y_train_order = y_train_order\n",
    "        # users: no of student datapoints\n",
    "        self.users = np.shape(x_train)[0]\n",
    "        self.validation_split = validation_split\n",
    "        self.validation_data = validation_data\n",
    "        self.optimizer = optimizer\n",
    "        self.callbacks = callbacks\n",
    "        print (\"DKTnet initialization done\")\n",
    "        \n",
    "        \n",
    "\n",
    "        \n",
    "    def LossModel(y_train,dense_out):\n",
    "\n",
    "        dense_output= Input(batch_shape=(None, None, self.input_dim_order), name='predicted_prob')\n",
    "        y_order=Input(batch_shape=(None, None, self.input_dim_order), name='skill_array')\n",
    "   \n",
    "        merged = multiply([dense_out, y_order])\n",
    "         ## 6. Chooses the max value(which is a non zero number in merged) from the output of merged layer\n",
    "        # this will reduce dimension from skill_num to 1 for each timestep\n",
    "\n",
    "        reduced = Lambda(reduce_dim, output_shape=reduce_dim_shape)(merged)\n",
    "        cce = tf.losses.softmax_cross_entropy(self.y_train,reduced)\n",
    "        loss_m = Model(inputs=[dense_output,y_order], outputs=cce)\n",
    "        #it's important to make this model not trainable if it has weights \n",
    "        #(you should probably set these weights manually if that's the case)    \n",
    "        loss_m.trainable = False\n",
    "        return loss_m\n",
    "\n",
    "    def build_train_on_batch(self):\n",
    "            ## 1. First layer for the input (x_t), creates a tensor object\n",
    "            x = Input(batch_shape=(None, None, self.input_dim), name='x')\n",
    "\n",
    "            ## 2. Mask unknown or anomalous valued timesteps in x\n",
    "            # the timestep will be masked (skipped) if all values in the input tensor\n",
    "            #  at that timestep are equal to mask_value\n",
    "            masked = Masking(mask_value=0)(x)\n",
    "\n",
    "            ## 3. Add a lstm layer, return sequences is True to allow output have same\n",
    "            # dimension as number of timesteps in input\n",
    "            lstm_out = LSTM(self.hidden_layer_size, return_sequences=True)(masked)\n",
    "\n",
    "            ## 4. Add a fully connected layer on lstm layer, \n",
    "            ### this gives us probabilities of all events at differnt timesteps\n",
    "            dense_out = Dense(self.input_dim_order, activation='sigmoid')(lstm_out)\n",
    "            \n",
    "\n",
    "            \n",
    "            \n",
    "            def get_probability_of_timestep_event(x):\n",
    "                #Custom tensor arithmatic from backend K\n",
    "                # chooses the max value from the output of previous layer\n",
    "                # this will reduce dimension from one hot of skill_num to 1 for each timestep\n",
    "                x = K.max(x, axis=2, keepdims=True)\n",
    "                return x\n",
    "\n",
    "        \n",
    "             ## 5.1 Get problem event encoding ONLY: \n",
    "            #  ASSUMPTION:that skill dict has problem events only from keys 1:input_dim_order\n",
    "            \n",
    "            def get_skill_array(x):\n",
    "                return x[:,:,:self.input_dim_order]\n",
    "  \n",
    "            \n",
    "#             y_order=Lambda(get_skill_array,output_shape=lambda s: (s[0], s[1],self.input_dim_order))(x)\n",
    "            \n",
    "#             ## 5.2 In dense output only retain probability of event at that timestep all others 0\n",
    "#             merged = multiply([dense_out, y_order])\n",
    "\n",
    "#             ## 6. Chooses the max value from the output of merged which is the prob\n",
    "#                 # this will reduce dimension from skill_num to 1 for each timestep\n",
    "\n",
    "#             reduced = Lambda(get_probability_of_timestep_event , output_shape=lambda s: (s[0], s[1],1))(merged)\n",
    "    \n",
    "#             ## 7. Creates model object with specified input and output\n",
    "#             self.model = Model(inputs=x, outputs=reduced)\n",
    "\n",
    "#             ## 8. Compile model by assigning loss function for backpropagtion\n",
    "#             self.model.compile(optimizer=self.optimizer,\n",
    "#                                loss='binary_crossentropy',\n",
    "#                                metrics=['accuracy'])\n",
    "\n",
    "#             print('Summary of the model')\n",
    "#             self.model.summary()\n",
    "\n",
    "\n",
    "            \n",
    "            def custom_loss(y_train,dense_out):\n",
    "                '''\n",
    "                using crossentropy, choose from dense_out, the probabilities corresponding to event attemted\n",
    "                at that timesetep. Create a tensor object of that accepts skill_array i. e one hot encoded skill sequence\n",
    "                then mask the dense_out using that skill array\n",
    "                '''\n",
    "                print(\"using custom loss.....\")\n",
    "\n",
    "                \n",
    "                y_order=Lambda(get_skill_array,output_shape=lambda s: (s[0], s[1],self.input_dim_order))(x)\n",
    "            \n",
    "\n",
    "                ## 5.2 In dense output only retain probability of event at that timestep all others 0\n",
    "                merged = multiply([dense_out, y_order])\n",
    "\n",
    "                ## 6. Chooses the max value from the output of merged which is the prob\n",
    "                    # this will reduce dimension from skill_num to 1 for each timestep\n",
    "\n",
    "                reduced = Lambda(get_probability_of_timestep_event , output_shape=lambda s: (s[0], s[1],1))(merged)\n",
    "\n",
    "                cce = K.mean(K.binary_crossentropy(y_train, reduced ))#, axis=-1)\n",
    "                return cce\n",
    "\n",
    "\n",
    "            \n",
    "            def custom_metric_accuracy(y_train,dense_out):\n",
    "                '''\n",
    "                using crossentropy, choose from dense_out, the probabilities corresponding to event attemted\n",
    "                at that timesetep. Create a tensor object of that accepts skill_array i. e one hot encoded skill sequence\n",
    "                then mask the dense_out using that skill array\n",
    "                '''\n",
    "                print(\"using custom metric.....\")\n",
    "                def get_response_array(x):\n",
    "                    return x[:,:,-self.input_dim_order:]\n",
    "                \n",
    "                \n",
    "                \n",
    "                actual_response=Lambda(get_response_array,output_shape=lambda s: (s[0], s[1],self.input_dim_order))(x)\n",
    "                print(actual_response.get_shape(),\"actual response\")\n",
    "                def idx_max_prob(x):\n",
    "                    max_idx= K.argmax(x,axis=-1)\n",
    "#                         convert to one hot, to tackle,incorrect question argmax\n",
    "                    one_hot_idx=tf.one_hot(max_idx,\n",
    "                                self.input_dim_order,\n",
    "                                on_value=1.0,\n",
    "                                off_value=0.0,\n",
    "                                axis=-1)\n",
    "                    return one_hot_idx\n",
    "        \n",
    "                max_predicted_prob = Lambda(idx_max_prob,output_shape=lambda s: (s[0], s[1],self.input_dim_order))(dense_out)\n",
    "                print( max_predicted_prob.get_shape(),\" max_predicted_prob\")\n",
    "                # we use merging, we want to find how many 1-1 matchings are there\n",
    "                merged_metric = multiply([actual_response,  max_predicted_prob])\n",
    "\n",
    "\n",
    "                accuracy = K.mean(K.sum(merged_metric,axis=-1))\n",
    "                print(accuracy.get_shape())\n",
    "                return accuracy\n",
    "\n",
    "\n",
    "            ## 7.Creates model object with specified input and output\n",
    "                #CHANGED: OUTPUTS: TO GET probabilities at all timesteps as output.\n",
    "\n",
    "            self.model = Model(inputs=x, outputs=dense_out)\n",
    "\n",
    "            ## 8. Compile model by assigning loss function for backpropagtion\n",
    "            self.model.compile(optimizer=self.optimizer,\n",
    "                               loss=custom_loss,\n",
    "                               metrics=[custom_metric_accuracy])\n",
    "\n",
    "            print('Summary of the model')\n",
    "            self.model.summary()\n",
    "   \n",
    "\n",
    "    def train_on_batch(self, x_train,y_train,y_train_order):\n",
    "# y_train_order: not used\n",
    "        self.model.train_on_batch(x_train, y_train)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    def test_on_batch(self, x_val, y_val,y_train_order):\n",
    "        \n",
    "        # y_train_order: not used\n",
    "        \"\"\"\n",
    "       Test the model on a single batch of samples\n",
    "       :return: Scalar test loss (if the model has a single output and no metrics) or list of scalars (if the model has multiple outputs and/or metrics).\n",
    "       The attribute model.metrics_names will give you the display labels for the scalar outputs.\n",
    "       \"\"\"\n",
    "        print(self.model.metrics_names)\n",
    "        return self.model.test_on_batch(x_val, y_val)\n",
    "\n",
    "    def predict(self, x_val,y_train_order):\n",
    "#              # y_train_order: not used\n",
    "        return self.model.predict_on_batch(x_val)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "class DKTnet():\n",
    "\n",
    "    def __init__(self, \n",
    "                input_dim, \n",
    "                input_dim_order, \n",
    "                hidden_layer_size, \n",
    "                batch_size, \n",
    "                epochs,\n",
    "                x_train=[], \n",
    "                y_train=[], \n",
    "                y_train_order=[],\n",
    "                validation_split=0.0,\n",
    "                validation_data=None,\n",
    "                optimizer='adam',\n",
    "                callbacks=None):\n",
    "        \"\"\"\n",
    "\n",
    "        :param input_dim: dimension of the input at one timestamp (dimension of x_t= 2*num_skills)\n",
    "        :param input_dim_order: dimension of the one-hot representation of problem to check order of occurence(=num_skills)\n",
    "        :param hidden_layer_size: number of nodes in hidden layer\n",
    "        :param x_train: 3D matrix of size (samples, number of timestamp/sequence length, dimension of input vec (x_t) )\n",
    "        :param y_train: a matrix of responses (samples,number of timestamp/sequence length)\n",
    "        :param y_train_order: shape of output equal to number of timesteps\n",
    "        :param validation_split:\n",
    "        :param validation_data:\n",
    "        :param optimizer:\n",
    "        :param callbacks:\n",
    "\n",
    "        \"\"\"\n",
    "        ## input dim is the dimension of the input at one timestamp (dimension of x_t)\n",
    "        self.input_dim = int(input_dim) #2* num_skills\n",
    "\n",
    "        ## input_dim_order is the dimension of the one-hot representation of problem\n",
    "        ## CHECK: order of occurence of responses should be according to timestamp\n",
    "        self.input_dim_order = int(input_dim_order)#num_skills\n",
    "\n",
    "        self.hidden_layer_size = int(hidden_layer_size)\n",
    "        self.batch_size = int(batch_size)\n",
    "        self.epochs = int(epochs)\n",
    "\n",
    "        ## x_train is a 3D matrix of size (samples, number of timestamp, dimension of input vec (x_t) )\n",
    "        ## in cognitive tutor # of students * # total responses * # input_dim(2*NO SKILLS)\n",
    "        self.x_train = x_train\n",
    "        ## y_train is a matrix of (samples one hot representation according to problem output value at each timestamp (y_t) )\n",
    "        self.y_train = y_train\n",
    "        ## y_train_order is the one hot representation of problem according to timestamp starting from\n",
    "        ## t=1 if training starts at t=0\n",
    "        self.y_train_order = y_train_order\n",
    "        # users: no of student datapoints\n",
    "        self.users = np.shape(x_train)[0]\n",
    "        self.validation_split = validation_split\n",
    "        self.validation_data = validation_data\n",
    "        self.optimizer = optimizer\n",
    "        self.callbacks = callbacks\n",
    "        print (\"DKTnet initialization done\")\n",
    "\n",
    "    def build_train_on_batch(self):\n",
    "        ## 1. First layer for the input (x_t), creates a tensor object\n",
    "        x = Input(batch_shape=(None, None, self.input_dim), name='x')\n",
    "\n",
    "        ## 2. Mask unknown or anomalous valued timesteps in x\n",
    "        # the timestep will be masked (skipped) if all values in the input tensor\n",
    "        #  at that timestep are equal to mask_value\n",
    "        masked = Masking(mask_value=-1)(x)\n",
    "\n",
    "        ## 3. Add a lstm layer, return sequences is True to allow output have same\n",
    "        # dimension as number of timesteps in input\n",
    "        lstm_out = LSTM(self.hidden_layer_size, return_sequences=True)(masked)\n",
    "\n",
    "        ## 4. Add a fully connected layer on lstm layer\n",
    "\n",
    "        dense_out = Dense(self.input_dim_order, activation='sigmoid')(lstm_out)\n",
    "        ## 5. Create  a tensor object --not sure if its required\n",
    "        y_order = Input(batch_shape=(None, None, self.input_dim_order), name='y_order')\n",
    "        merged = multiply([dense_out, y_order])\n",
    "\n",
    "        def reduce_dim(x):\n",
    "            #Custom tensor arithmatic from backend K\n",
    "            # chooses the max value from the output of previous layer\n",
    "            # this will reduce dimension from skill_num to 1 for each timestep\n",
    "            x = K.max(x, axis=2, keepdims=True)\n",
    "            return x\n",
    "\n",
    "        def reduce_dim_shape(input_shape):\n",
    "            shape = list(input_shape)\n",
    "            shape[-1] = 1\n",
    "            return tuple(shape)\n",
    "\n",
    "        ## 6. Chooses the max value from the output of previous layer\n",
    "            # this will reduce dimension from skill_num to 1 for each timestep\n",
    "        reduced = Lambda(reduce_dim, output_shape=reduce_dim_shape)(merged)\n",
    "\n",
    "        ## 7. Creates model object with specified input and output\n",
    "        self.model = Model(inputs=[x, y_order], outputs=reduced)\n",
    "\n",
    "        ## 8. Compile model by assigning loss function for backpropagtion\n",
    "        self.model.compile(optimizer=self.optimizer,\n",
    "                           loss='binary_crossentropy',\n",
    "                           metrics=['accuracy'])\n",
    "\n",
    "        print('Summary of the model')\n",
    "        self.model.summary()\n",
    "\n",
    "\n",
    "\n",
    "    def train_on_batch(self, x_train, y_train, y_train_order):\n",
    "\n",
    "        self.model.train_on_batch([x_train, y_train_order], y_train)\n",
    "\n",
    "\n",
    "\n",
    "    def test_on_batch(self, x_val, y_val, y_val_order):\n",
    "        \"\"\"\n",
    "       Test the model on a single batch of samples.\n",
    "       :param x_train:\n",
    "       :param y_train:\n",
    "       :param y_train_order:\n",
    "       :return: Scalar test loss (if the model has a single output and no metrics) or list of scalars (if the model has multiple outputs and/or metrics).\n",
    "       The attribute model.metrics_names will give you the display labels for the scalar outputs.\n",
    "       \"\"\"\n",
    "        print(self.model.metrics_names)\n",
    "        return self.model.test_on_batch([x_val, y_val_order], y_val)\n",
    "\n",
    "\n",
    "\n",
    "    def predict(self, x_val, y_val_order):\n",
    "        return self.model.predict([x_val, y_val_order])\n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "  \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#testing :\n",
    "from keras.models import Model\n",
    "from keras.layers import Input, Dropout, Masking, Dense, Embedding\n",
    "from keras.layers import Embedding\n",
    "\n",
    "\n",
    "class DKTnettest():\n",
    "\n",
    "    def __init__(self, \n",
    "                input_dim, \n",
    "                input_dim_order, \n",
    "                hidden_layer_size, \n",
    "                batch_size, \n",
    "                epochs,\n",
    "                x_train=[], \n",
    "                y_train=[], \n",
    "                y_train_order=[],\n",
    "                validation_split=0.0,\n",
    "                validation_data=None,\n",
    "                optimizer='adam',\n",
    "                callbacks=None,\n",
    "                problem_no=336):\n",
    "        \"\"\"\n",
    "\n",
    "        :param input_dim: dimension of the input at one timestamp (dimension of x_t= 2*num_skills)\n",
    "        :param input_dim_order: dimension of the one-hot representation of problem to check order of occurence(=num_skills)\n",
    "        :param hidden_layer_size: number of nodes in hidden layer\n",
    "        :param x_train: 3D matrix of size (samples, number of timestamp/sequence length, dimension of input vec (x_t) )\n",
    "        :param y_train: a matrix of responses (samples,number of timestamp/sequence length)\n",
    "        :param y_train_order: shape of output equal to number of timesteps\n",
    "        :param validation_split:\n",
    "        :param validation_data:\n",
    "        :param optimizer:\n",
    "        :param callbacks:\n",
    "\n",
    "        \"\"\"\n",
    "        ## input dim is the dimension of the input at one timestamp (dimension of x_t)\n",
    "        self.input_dim = int(input_dim) #2* num_skills\n",
    "\n",
    "        ## input_dim_order is the dimension of the one-hot representation of problem\n",
    "        ## CHECK: order of occurence of responses should be according to timestamp\n",
    "        self.input_dim_order = int(input_dim_order)#num_skills\n",
    "\n",
    "        self.hidden_layer_size = int(hidden_layer_size)\n",
    "        self.batch_size = int(batch_size)\n",
    "        self.epochs = int(epochs)\n",
    "\n",
    "        ## x_train is a 3D matrix of size (samples, number of timestamp, dimension of input vec (x_t) )\n",
    "        ## in cognitive tutor # of students * # total responses * # input_dim(2*NO SKILLS)\n",
    "        self.x_train = x_train\n",
    "        ## y_train is a matrix of (samples one hot representation according to problem output value at each timestamp (y_t) )\n",
    "        self.y_train = y_train\n",
    "        ## y_train_order is the one hot representation of problem according to timestamp starting from\n",
    "        ## t=1 if training starts at t=0\n",
    "        self.y_train_order = y_train_order\n",
    "        # users: no of student datapoints\n",
    "        self.users = np.shape(x_train)[0]\n",
    "        self.validation_split = validation_split\n",
    "        self.validation_data = validation_data\n",
    "        self.optimizer = optimizer\n",
    "        self.callbacks = callbacks\n",
    "        print (\"DKTnet initialization done\")\n",
    "\n",
    "    def build_train_on_batch(self):\n",
    "        ## 1. First layer for the input (x_t), creates a tensor object\n",
    "        x = Input(batch_shape=(None, None, self.input_dim), name='x')\n",
    "\n",
    "        ## 2. Mask unknown or anomalous valued timesteps in x\n",
    "        # the timestep will be masked (skipped) if all values in the input tensor\n",
    "        #  at that timestep are equal to mask_value\n",
    "        masked = Masking(mask_value=0)(x)\n",
    "\n",
    "        ## 3. Add a lstm layer, return sequences is True to allow output have same\n",
    "        # dimension as number of timesteps in input\n",
    "        lstm_out = LSTM(self.hidden_layer_size, return_sequences=True)(masked)\n",
    "\n",
    "        ## 4. Add a fully connected layer on lstm layer\n",
    "\n",
    "        dense_out = Dense(self.input_dim_order, activation='sigmoid')(lstm_out)\n",
    "       \n",
    "      \n",
    "\n",
    "        def reduce_dim(x):\n",
    "            #Custom tensor arithmatic from backend K\n",
    "            # chooses the max value from the output of previous layer\n",
    "            # this will reduce dimension from skill_num to 1 for each timestep\n",
    "            x = K.max(x, axis=2, keepdims=True)\n",
    "            return x\n",
    "\n",
    "        def get_skill_array(x):\n",
    "            return x[:,:,:self.input_dim_order]\n",
    "        \n",
    "        \n",
    "        \n",
    "         ## 5. Create  a tensor object --not sure if its required\n",
    "#         y_order = Input(batch_shape=(None, None, self.input_dim_order), name='y_order')\n",
    "\n",
    "#         y_order=x[:,:,:self.input_dim_order]\n",
    "        y_order=Lambda(get_skill_array,output_shape=lambda s: (s[0], s[1],self.input_dim_order))(x)\n",
    "\n",
    "        merged = multiply([dense_out, y_order])\n",
    "\n",
    "        ## 6. Chooses the max value from the output of previous layer\n",
    "            # this will reduce dimension from skill_num to 1 for each timestep\n",
    "#         reduced = Lambda(reduce_dim )(merged)\n",
    "        reduced = Lambda(reduce_dim , output_shape=lambda s: (s[0], s[1],1))(merged)\n",
    "        print(\"DIM OF y_order,reduced \",y_order.get_shape(),reduced.get_shape())\n",
    "        \n",
    "        \n",
    "        \n",
    "        def custom_metric_accuracy(u,v):\n",
    "                '''\n",
    "                using crossentropy, choose from dense_out, the probabilities corresponding to event attemted\n",
    "                at that timesetep. Create a tensor object of that accepts skill_array i. e one hot encoded skill sequence\n",
    "                then mask the dense_out using that skill array\n",
    "                '''\n",
    "                print(\"using custom metric.....\")\n",
    "                def get_response_array(x):\n",
    "                    return x[:,:,-self.input_dim_order:]\n",
    "                \n",
    "                \n",
    "                \n",
    "                actual_response=Lambda(get_response_array,output_shape=lambda s: (s[0], s[1],self.input_dim_order))(x)\n",
    "                print(actual_response.get_shape(),\"actual response\")\n",
    "                def idx_max_prob(x):\n",
    "                    max_idx= K.argmax(x,axis=-1)\n",
    "#                         convert to one hot, to tackle,incorrect question argmax\n",
    "                    one_hot_idx=tf.one_hot(max_idx,\n",
    "                                self.input_dim_order,\n",
    "                                on_value=1.0,\n",
    "                                off_value=0.0,\n",
    "                                axis=-1)\n",
    "                    return one_hot_idx\n",
    "        \n",
    "                max_predicted_prob = Lambda(idx_max_prob,output_shape=lambda s: (s[0], s[1],self.input_dim_order))(dense_out)\n",
    "                print( max_predicted_prob.get_shape(),\" max_predicted_prob\")\n",
    "                # we use merging, we want to find how many 1-1 matchings are there\n",
    "                merged_metric = multiply([actual_response,  max_predicted_prob])\n",
    "\n",
    "\n",
    "                accuracy = K.mean(K.sum(merged_metric,axis=-1))\n",
    "                print(accuracy.get_shape())\n",
    "                return accuracy\n",
    "\n",
    "        ## 7. Creates model object with specified input and output\n",
    "        self.model = Model(inputs=x, outputs=reduced)\n",
    "\n",
    "        ## 8. Compile model by assigning loss function for backpropagtion\n",
    "        self.model.compile(optimizer=self.optimizer,\n",
    "                           loss='binary_crossentropy',\n",
    "                           metrics=['accuracy',custom_metric_accuracy])\n",
    "\n",
    "        print('Summary of the model')\n",
    "        self.model.summary()\n",
    "        \n",
    "    def train_on_batch(self, x_train,y_train,y_train_order):\n",
    "# y_train_order: not used\n",
    "        self.model.train_on_batch(x_train, y_train)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    def test_on_batch(self, x_val, y_val,y_train_order):\n",
    "        \n",
    "        # y_train_order: not used\n",
    "        \"\"\"\n",
    "       Test the model on a single batch of samples\n",
    "       :return: Scalar test loss (if the model has a single output and no metrics) or list of scalars (if the model has multiple outputs and/or metrics).\n",
    "       The attribute model.metrics_names will give you the display labels for the scalar outputs.\n",
    "       \"\"\"\n",
    "        print(self.model.metrics_names)\n",
    "        return self.model.test_on_batch(x_val, y_val)\n",
    "\n",
    "    def predict(self, x_val,y_train_order):\n",
    "#              # y_train_order: not used\n",
    "        return self.model.predict_on_batch(x_val)\n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# train.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "from keras.callbacks import ModelCheckpoint, EarlyStopping, ReduceLROnPlateau\n",
    "import argparse\n",
    "\n",
    "# from DKT import DKTnet\n",
    "# from data_helper import load_data, one_hot, preprocess\n",
    "\n",
    "def get_callbacks():\n",
    "    '''\n",
    "    Some callback functions that you may find useful.\n",
    "    Please refer to https://keras.io/callbacks/ for more detailed explaination\n",
    "    '''\n",
    "    checkpoint = ModelCheckpoint('my_model', \n",
    "                                 monitor='val_loss',\n",
    "                                 verbose=2, \n",
    "                                 save_best_only=True)\n",
    "    early_stopping = EarlyStopping(monitor='val_loss', \n",
    "                                   patience=2)\n",
    "    reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.1, patience=0, min_lr=1e-4)\n",
    "    return [checkpoint, early_stopping, reduce_lr]\n",
    "\n",
    "\n",
    "\n",
    "def batch_generator(skill_array, response_array, skill_response_array, batch_size=64, shuffle=True):\n",
    "    \"\"\"\n",
    "    return: batches of data from the original data set for training\n",
    "    \"\"\"\n",
    "    sample_num = skill_array.shape[0]\n",
    "    if shuffle:\n",
    "        shuffled_indices = np.random.permutation(sample_num)\n",
    "        skill_array = skill_array.copy()[shuffled_indices]\n",
    "        response_array = response_array.copy()[shuffled_indices]\n",
    "        skill_response_array = skill_response_array.copy()[shuffled_indices]\n",
    "        print('Training set shuffled')\n",
    "    for ndx in range(0, sample_num, batch_size):\n",
    "        skill_array_batch = skill_array[ndx:min(ndx+batch_size, sample_num)]\n",
    "        response_array_batch = response_array[ndx:min(ndx+batch_size, sample_num)]\n",
    "        skill_response_array_batch = skill_response_array[ndx:min(ndx+batch_size, sample_num)]\n",
    "        yield skill_response_array_batch, response_array_batch, skill_array_batch\n",
    "\n",
    "def create_validation_data(skill_array, response_array, skill_response_array,size=0.2):\n",
    "    \"\"\"\n",
    "    return: split of data from the original data set for testing\n",
    "    \"\"\"\n",
    "    sample_num = skill_array.shape[0]\n",
    "    shuffled_indices = np.random.permutation(sample_num)\n",
    "    skill_array = skill_array.copy()[shuffled_indices]\n",
    "    response_array = response_array.copy()[shuffled_indices]\n",
    "    skill_response_array = skill_response_array.copy()[shuffled_indices]\n",
    "    print('Data set shuffled, preparing for split')\n",
    "    split_index=int(size*sample_num)\n",
    "    train_index=sample_num-split_index\n",
    "    print('train:', train_index, \"test:\",split_index)\n",
    "    skill_array_train = skill_array[0:train_index]\n",
    "    response_array_train = response_array[0:train_index]\n",
    "    skill_response_array_train = skill_response_array[0:train_index]\n",
    "    \n",
    "    skill_array_test = skill_array[train_index:]\n",
    "    response_array_test = response_array[train_index:]\n",
    "    skill_response_array_test = skill_response_array[train_index:]\n",
    "    \n",
    "    return skill_array_train, response_array_train, skill_response_array_train,skill_array_test,response_array_test,skill_response_array_test\n",
    "\n",
    "\n",
    "def train_on_batch(skill_array, response_array, skill_response_array,custom_loss=False,):\n",
    "    \"\"\"This function creates a DKT MODEL object using DKT.py and\n",
    "    trains it using the batched data\"\"\"\n",
    "\n",
    "    input_dim = skill_response_array.shape[-1]  #2* num_skills\n",
    "#     input_dim_order = skill_array.shape[-1] #num_skills\n",
    "    input_dim_order = 336\n",
    "    hidden_layer_size = 40\n",
    "    batch_size = 64\n",
    "    epochs = 5\n",
    "    print(\"batch size==\",batch_size)\n",
    "    print(\"epoch size=\", epochs)\n",
    "    print(\"input_dim_order\",input_dim_order)\n",
    "    print(\"input_dim\",input_dim)\n",
    "    \n",
    "\n",
    "    '''\n",
    "    parameters like batch_size, epochs x_train, y_train, y_train_order and validations are useless\n",
    "    if you are doing a training by batch\n",
    "    '''\n",
    "    if custom_loss ==False:\n",
    "        dkt = DKTnettest(input_dim, \n",
    "                    input_dim_order, \n",
    "                    hidden_layer_size, \n",
    "                    batch_size, \n",
    "                    epochs,\n",
    "                    x_train=skill_response_array[:, :, :], \n",
    "                    y_train=response_array[:, :, np.newaxis], \n",
    "                    y_train_order=skill_array[:, :, :],\n",
    "                    validation_split=0.2,\n",
    "                    validation_data=0.2,\n",
    "                    optimizer='adam',\n",
    "                    callbacks=None)\n",
    "        \n",
    "    else:\n",
    "        dkt = DKTcustomloss(input_dim, \n",
    "                    input_dim_order, \n",
    "                    hidden_layer_size, \n",
    "                    batch_size, \n",
    "                    epochs,\n",
    "                    x_train=skill_response_array[:, :, :], \n",
    "                    y_train=response_array[:, :, np.newaxis], \n",
    "                    y_train_order=skill_array[:, :, :],\n",
    "                    validation_split=0.2,\n",
    "                    validation_data=0.2,\n",
    "                    optimizer='adam',\n",
    "                    callbacks=None)\n",
    "        \n",
    "        \n",
    "    print('x_train.shape,y_train.shape')\n",
    "   \n",
    "    print(skill_response_array[:, :, :].shape,response_array[:,:,np.newaxis].shape)\n",
    "   \n",
    "    dkt.build_train_on_batch()\n",
    "    \n",
    "\n",
    "    '''\n",
    "    For simplification, we are over fitting on the training set here.\n",
    "    In your model, you should do a train-test split or cross-validation which can be found in sklearn package.\n",
    "    '''\n",
    "    skill_array_train, response_array_train, skill_response_array_train,skill_array_test,response_array_test,skill_response_array_test=create_validation_data(skill_array, response_array, skill_response_array,size=dkt.validation_split)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    for e in range(epochs):\n",
    "        print('***Epoch', e+1, 'starts****')\n",
    "        iteration = 0\n",
    "        total_iteration_num = 1 + (skill_array.shape[0] - 1) // batch_size\n",
    "        for skill_response_array_batch, response_array_batch, skill_array_batch in batch_generator(skill_array_train, response_array_train, skill_response_array_train, batch_size=batch_size):\n",
    "            dkt.train_on_batch(skill_response_array_batch[:, :, :],response_array_batch[:, :, np.newaxis],  skill_array_batch[:, :, :])\n",
    "            iteration += 1\n",
    "        print(\"iter: {}/{} done\".format(iteration, total_iteration_num))\n",
    "        \n",
    "        result = dkt.test_on_batch(skill_response_array_test[:, :, :],response_array_test[:, :, np.newaxis],  skill_array_test[:, 1:, :])\n",
    "        trainresult = dkt.test_on_batch(skill_response_array_train[:, :, :],response_array_train[:, :, np.newaxis],  skill_array_train[:, 1:, :])\n",
    "        print('Evalutaion training data result', trainresult)\n",
    "        print('Evalutaion validation data result', result)\n",
    "        '''\n",
    "        You should implement your own evaluation function here to evaluate your result on the validation set if each sample have different timesteps\n",
    "        '''\n",
    "    prediction = dkt.predict(skill_response_array[0:1, :, :],\n",
    "                                skill_array[0:1, 1:, :])\n",
    "\n",
    "#     print('Check Prediction Output:', prediction,response_array[:, :, np.newaxis])\n",
    "    # print('Check shape:Input,prediction, y_train:',dkt.x_train.shape, prediction.shape,dkt.y_train[0:1].shape)\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "# if __name__ == '__main__':\n",
    "#     parser = argparse.ArgumentParser()\n",
    "#     parser.add_argument('-S',\"--skill_df\", type=str, required=True)\n",
    "#     parser.add_argument('-R',\"--response_df\",type=str, required=True)\n",
    "#     parser.add_argument('-dict',\"--skill_dict\", type=str, required=True)\n",
    "#     args = parser.parse_args()\n",
    "#     print(args)\n",
    "\n",
    "#     response_df,skill_df,skill_dict=load_data(args.skill_df,args.response_df,args.skill_dict)\n",
    "#     # response_df,skill_df,skill_dict=load_data()\n",
    "#     skills_num = len(skill_dict)\n",
    "#     print('Number of skills are :{}'.format(skills_num))\n",
    "#     skill_array, response_array, skill_response_array = preprocess(skill_df, response_df, skills_num)\n",
    "#     # train(skill_array, response_array, skill_response_array)\n",
    "#     train_on_batch(skill_array, response_array, skill_response_array)\n",
    "\n",
    "#     # python train.py -S skill_df_delft_15.csv -R response_df_delft_15.csv -dict skill_dict_delft_15.json\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "skill_matrix .shape,response_array.shape\n",
      "(9242, 100) (9242, 100)\n",
      "Number of non-problem events: 291\n",
      "627\n",
      "Check encode in skill and one hot skill: 29930 29930.0\n",
      "Check number correct in response and one hot response: 4829 4829.0\n",
      "skill_array.shape,response_one_hot.shape,skill_response_array.shape\n",
      "(500, 100, 627) (500, 100, 336) (500, 100, 963)\n",
      "skill_array.shape,response_array.shape,skill_response_array.shape\n",
      "(500, 100, 627) (500, 100) (500, 100, 963)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# \"\"\"phase 2- delft 15\"\"\"\n",
    "\n",
    "data_dir='code/delft15_phase2/'\n",
    "event_dict=(data_dir+'all_event_dict_delft15.json')\n",
    "skill=os.path.join(data_dir+\"event_df_delft_15.csv\")\n",
    "response=os.path.join(data_dir+\"response_df_delft_15.csv\")\n",
    "\n",
    "\n",
    "# subset for testing\n",
    "\n",
    "skill_matrix,response_array,problem_num, non_problem_event_num=load_data(skill,response,event_dict,problem_num=336,is_behaviour=True)\n",
    "skill_matrix=skill_matrix[:500,:]\n",
    "response_array=response_array[:500,:]\n",
    "\n",
    "# load preprocess in each batch, put in train_batch fynction\n",
    "print('Number of non-problem events:', non_problem_event_num)\n",
    "skill_array, response_array, skill_response_array=preprocess(skill_matrix,response_array,problem_num, non_problem_event_num)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch size== 64\n",
      "epoch size= 5\n",
      "input_dim_order 336\n",
      "input_dim 963\n",
      "DKTnet initialization done\n",
      "x_train.shape,y_train.shape\n",
      "(500, 100, 963) (500, 100, 1)\n",
      "using custom loss.....\n",
      "using custom metric.....\n",
      "(?, ?, 336) actual response\n",
      "(?, ?, 336)  max_predicted_prob\n",
      "()\n",
      "Summary of the model\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "x (InputLayer)               (None, None, 963)         0         \n",
      "_________________________________________________________________\n",
      "masking_2 (Masking)          (None, None, 963)         0         \n",
      "_________________________________________________________________\n",
      "lstm_2 (LSTM)                (None, None, 40)          160640    \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, None, 336)         13776     \n",
      "=================================================================\n",
      "Total params: 174,416\n",
      "Trainable params: 174,416\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Data set shuffled, preparing for split\n",
      "train: 400 test: 100\n",
      "***Epoch 1 starts****\n",
      "Training set shuffled\n",
      "iter: 7/8 done\n",
      "['loss', 'custom_metric_accuracy']\n",
      "['loss', 'custom_metric_accuracy']\n"
     ]
    },
    {
     "ename": "ResourceExhaustedError",
     "evalue": "OOM when allocating tensor with shape[100,400,963] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc\n\t [[Node: lstm_2/transpose = Transpose[T=DT_FLOAT, Tperm=DT_INT32, _device=\"/job:localhost/replica:0/task:0/device:GPU:0\"](masking_2/mul, lstm_2/transpose/perm)]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\n\n\t [[Node: metrics_1/custom_metric_accuracy/Mean_2/_321 = _Recv[client_terminated=false, recv_device=\"/job:localhost/replica:0/task:0/device:CPU:0\", send_device=\"/job:localhost/replica:0/task:0/device:GPU:0\", send_device_incarnation=1, tensor_name=\"edge_406_metrics_1/custom_metric_accuracy/Mean_2\", tensor_type=DT_FLOAT, _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"]()]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\n\n\nCaused by op 'lstm_2/transpose', defined at:\n  File \"/usr/lib/python3.5/runpy.py\", line 184, in _run_module_as_main\n    \"__main__\", mod_spec)\n  File \"/usr/lib/python3.5/runpy.py\", line 85, in _run_code\n    exec(code, run_globals)\n  File \"/usr/local/lib/python3.5/dist-packages/ipykernel_launcher.py\", line 16, in <module>\n    app.launch_new_instance()\n  File \"/usr/local/lib/python3.5/dist-packages/traitlets/config/application.py\", line 658, in launch_instance\n    app.start()\n  File \"/usr/local/lib/python3.5/dist-packages/ipykernel/kernelapp.py\", line 486, in start\n    self.io_loop.start()\n  File \"/usr/local/lib/python3.5/dist-packages/tornado/platform/asyncio.py\", line 112, in start\n    self.asyncio_loop.run_forever()\n  File \"/usr/lib/python3.5/asyncio/base_events.py\", line 345, in run_forever\n    self._run_once()\n  File \"/usr/lib/python3.5/asyncio/base_events.py\", line 1312, in _run_once\n    handle._run()\n  File \"/usr/lib/python3.5/asyncio/events.py\", line 125, in _run\n    self._callback(*self._args)\n  File \"/usr/local/lib/python3.5/dist-packages/tornado/platform/asyncio.py\", line 102, in _handle_events\n    handler_func(fileobj, events)\n  File \"/usr/local/lib/python3.5/dist-packages/tornado/stack_context.py\", line 276, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/usr/local/lib/python3.5/dist-packages/zmq/eventloop/zmqstream.py\", line 450, in _handle_events\n    self._handle_recv()\n  File \"/usr/local/lib/python3.5/dist-packages/zmq/eventloop/zmqstream.py\", line 480, in _handle_recv\n    self._run_callback(callback, msg)\n  File \"/usr/local/lib/python3.5/dist-packages/zmq/eventloop/zmqstream.py\", line 432, in _run_callback\n    callback(*args, **kwargs)\n  File \"/usr/local/lib/python3.5/dist-packages/tornado/stack_context.py\", line 276, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/usr/local/lib/python3.5/dist-packages/ipykernel/kernelbase.py\", line 283, in dispatcher\n    return self.dispatch_shell(stream, msg)\n  File \"/usr/local/lib/python3.5/dist-packages/ipykernel/kernelbase.py\", line 233, in dispatch_shell\n    handler(stream, idents, msg)\n  File \"/usr/local/lib/python3.5/dist-packages/ipykernel/kernelbase.py\", line 399, in execute_request\n    user_expressions, allow_stdin)\n  File \"/usr/local/lib/python3.5/dist-packages/ipykernel/ipkernel.py\", line 208, in do_execute\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"/usr/local/lib/python3.5/dist-packages/ipykernel/zmqshell.py\", line 537, in run_cell\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n  File \"/usr/local/lib/python3.5/dist-packages/IPython/core/interactiveshell.py\", line 2728, in run_cell\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"/usr/local/lib/python3.5/dist-packages/IPython/core/interactiveshell.py\", line 2856, in run_ast_nodes\n    if self.run_code(code, result):\n  File \"/usr/local/lib/python3.5/dist-packages/IPython/core/interactiveshell.py\", line 2910, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-12-3d7407813c09>\", line 1, in <module>\n    train_on_batch(skill_array,response_array, skill_response_array,custom_loss=True)\n  File \"<ipython-input-8-3bcacaa56c49>\", line 120, in train_on_batch\n    dkt.build_train_on_batch()\n  File \"<ipython-input-6-62915bb7d773>\", line 110, in build_train_on_batch\n    lstm_out = LSTM(self.hidden_layer_size, return_sequences=True)(masked)\n  File \"/usr/local/lib/python3.5/dist-packages/keras/layers/recurrent.py\", line 499, in __call__\n    return super(RNN, self).__call__(inputs, **kwargs)\n  File \"/usr/local/lib/python3.5/dist-packages/keras/engine/topology.py\", line 619, in __call__\n    output = self.call(inputs, **kwargs)\n  File \"/usr/local/lib/python3.5/dist-packages/keras/layers/recurrent.py\", line 2151, in call\n    initial_state=initial_state)\n  File \"/usr/local/lib/python3.5/dist-packages/keras/layers/recurrent.py\", line 608, in call\n    input_length=timesteps)\n  File \"/usr/local/lib/python3.5/dist-packages/keras/backend/tensorflow_backend.py\", line 2593, in rnn\n    inputs = tf.transpose(inputs, (axes))\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/ops/array_ops.py\", line 1476, in transpose\n    ret = transpose_fn(a, perm, name=name)\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/ops/gen_array_ops.py\", line 8215, in transpose\n    \"Transpose\", x=x, perm=perm, name=name)\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/framework/op_def_library.py\", line 787, in _apply_op_helper\n    op_def=op_def)\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/framework/ops.py\", line 3306, in create_op\n    op_def=op_def)\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/framework/ops.py\", line 1669, in __init__\n    self._traceback = self._graph._extract_stack()  # pylint: disable=protected-access\n\nResourceExhaustedError (see above for traceback): OOM when allocating tensor with shape[100,400,963] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc\n\t [[Node: lstm_2/transpose = Transpose[T=DT_FLOAT, Tperm=DT_INT32, _device=\"/job:localhost/replica:0/task:0/device:GPU:0\"](masking_2/mul, lstm_2/transpose/perm)]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\n\n\t [[Node: metrics_1/custom_metric_accuracy/Mean_2/_321 = _Recv[client_terminated=false, recv_device=\"/job:localhost/replica:0/task:0/device:CPU:0\", send_device=\"/job:localhost/replica:0/task:0/device:GPU:0\", send_device_incarnation=1, tensor_name=\"edge_406_metrics_1/custom_metric_accuracy/Mean_2\", tensor_type=DT_FLOAT, _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"]()]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\n\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mResourceExhaustedError\u001b[0m                    Traceback (most recent call last)",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1329\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1330\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1331\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1314\u001b[0m       return self._call_tf_sessionrun(\n\u001b[0;32m-> 1315\u001b[0;31m           options, feed_dict, fetch_list, target_list, run_metadata)\n\u001b[0m\u001b[1;32m   1316\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_call_tf_sessionrun\u001b[0;34m(self, options, feed_dict, fetch_list, target_list, run_metadata)\u001b[0m\n\u001b[1;32m   1422\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1423\u001b[0;31m             status, run_metadata)\n\u001b[0m\u001b[1;32m   1424\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/framework/errors_impl.py\u001b[0m in \u001b[0;36m__exit__\u001b[0;34m(self, type_arg, value_arg, traceback_arg)\u001b[0m\n\u001b[1;32m    515\u001b[0m             \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mc_api\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_Message\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstatus\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstatus\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 516\u001b[0;31m             c_api.TF_GetCode(self.status.status))\n\u001b[0m\u001b[1;32m    517\u001b[0m     \u001b[0;31m# Delete the underlying status object from memory otherwise it stays alive\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mResourceExhaustedError\u001b[0m: OOM when allocating tensor with shape[100,400,963] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc\n\t [[Node: lstm_2/transpose = Transpose[T=DT_FLOAT, Tperm=DT_INT32, _device=\"/job:localhost/replica:0/task:0/device:GPU:0\"](masking_2/mul, lstm_2/transpose/perm)]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\n\n\t [[Node: metrics_1/custom_metric_accuracy/Mean_2/_321 = _Recv[client_terminated=false, recv_device=\"/job:localhost/replica:0/task:0/device:CPU:0\", send_device=\"/job:localhost/replica:0/task:0/device:GPU:0\", send_device_incarnation=1, tensor_name=\"edge_406_metrics_1/custom_metric_accuracy/Mean_2\", tensor_type=DT_FLOAT, _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"]()]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\n",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mResourceExhaustedError\u001b[0m                    Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-12-3d7407813c09>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrain_on_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mskill_array\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mresponse_array\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mskill_response_array\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcustom_loss\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-8-3bcacaa56c49>\u001b[0m in \u001b[0;36mtrain_on_batch\u001b[0;34m(skill_array, response_array, skill_response_array, custom_loss)\u001b[0m\n\u001b[1;32m    140\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    141\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdkt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtest_on_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mskill_response_array_test\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mresponse_array_test\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnewaxis\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0mskill_array_test\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 142\u001b[0;31m         \u001b[0mtrainresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdkt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtest_on_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mskill_response_array_train\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mresponse_array_train\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnewaxis\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0mskill_array_train\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    143\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Evalutaion training data result'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrainresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    144\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Evalutaion validation data result'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-6-62915bb7d773>\u001b[0m in \u001b[0;36mtest_on_batch\u001b[0;34m(self, x_val, y_val, y_train_order)\u001b[0m\n\u001b[1;32m    245\u001b[0m        \"\"\"\n\u001b[1;32m    246\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmetrics_names\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 247\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtest_on_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_val\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_val\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    248\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    249\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx_val\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my_train_order\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mtest_on_batch\u001b[0;34m(self, x, y, sample_weight)\u001b[0m\n\u001b[1;32m   1922\u001b[0m             \u001b[0mins\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0msample_weights\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1923\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_test_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1924\u001b[0;31m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtest_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1925\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1926\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2476\u001b[0m         \u001b[0msession\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_session\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2477\u001b[0m         updated = session.run(fetches=fetches, feed_dict=feed_dict,\n\u001b[0;32m-> 2478\u001b[0;31m                               **self.session_kwargs)\n\u001b[0m\u001b[1;32m   2479\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mupdated\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2480\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    906\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    907\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 908\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    909\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    910\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1141\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1142\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m-> 1143\u001b[0;31m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[1;32m   1144\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1145\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1322\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1323\u001b[0m       return self._do_call(_run_fn, feeds, fetches, targets, options,\n\u001b[0;32m-> 1324\u001b[0;31m                            run_metadata)\n\u001b[0m\u001b[1;32m   1325\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1326\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1341\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1342\u001b[0m           \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1343\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnode_def\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1344\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1345\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_extend_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mResourceExhaustedError\u001b[0m: OOM when allocating tensor with shape[100,400,963] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc\n\t [[Node: lstm_2/transpose = Transpose[T=DT_FLOAT, Tperm=DT_INT32, _device=\"/job:localhost/replica:0/task:0/device:GPU:0\"](masking_2/mul, lstm_2/transpose/perm)]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\n\n\t [[Node: metrics_1/custom_metric_accuracy/Mean_2/_321 = _Recv[client_terminated=false, recv_device=\"/job:localhost/replica:0/task:0/device:CPU:0\", send_device=\"/job:localhost/replica:0/task:0/device:GPU:0\", send_device_incarnation=1, tensor_name=\"edge_406_metrics_1/custom_metric_accuracy/Mean_2\", tensor_type=DT_FLOAT, _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"]()]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\n\n\nCaused by op 'lstm_2/transpose', defined at:\n  File \"/usr/lib/python3.5/runpy.py\", line 184, in _run_module_as_main\n    \"__main__\", mod_spec)\n  File \"/usr/lib/python3.5/runpy.py\", line 85, in _run_code\n    exec(code, run_globals)\n  File \"/usr/local/lib/python3.5/dist-packages/ipykernel_launcher.py\", line 16, in <module>\n    app.launch_new_instance()\n  File \"/usr/local/lib/python3.5/dist-packages/traitlets/config/application.py\", line 658, in launch_instance\n    app.start()\n  File \"/usr/local/lib/python3.5/dist-packages/ipykernel/kernelapp.py\", line 486, in start\n    self.io_loop.start()\n  File \"/usr/local/lib/python3.5/dist-packages/tornado/platform/asyncio.py\", line 112, in start\n    self.asyncio_loop.run_forever()\n  File \"/usr/lib/python3.5/asyncio/base_events.py\", line 345, in run_forever\n    self._run_once()\n  File \"/usr/lib/python3.5/asyncio/base_events.py\", line 1312, in _run_once\n    handle._run()\n  File \"/usr/lib/python3.5/asyncio/events.py\", line 125, in _run\n    self._callback(*self._args)\n  File \"/usr/local/lib/python3.5/dist-packages/tornado/platform/asyncio.py\", line 102, in _handle_events\n    handler_func(fileobj, events)\n  File \"/usr/local/lib/python3.5/dist-packages/tornado/stack_context.py\", line 276, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/usr/local/lib/python3.5/dist-packages/zmq/eventloop/zmqstream.py\", line 450, in _handle_events\n    self._handle_recv()\n  File \"/usr/local/lib/python3.5/dist-packages/zmq/eventloop/zmqstream.py\", line 480, in _handle_recv\n    self._run_callback(callback, msg)\n  File \"/usr/local/lib/python3.5/dist-packages/zmq/eventloop/zmqstream.py\", line 432, in _run_callback\n    callback(*args, **kwargs)\n  File \"/usr/local/lib/python3.5/dist-packages/tornado/stack_context.py\", line 276, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/usr/local/lib/python3.5/dist-packages/ipykernel/kernelbase.py\", line 283, in dispatcher\n    return self.dispatch_shell(stream, msg)\n  File \"/usr/local/lib/python3.5/dist-packages/ipykernel/kernelbase.py\", line 233, in dispatch_shell\n    handler(stream, idents, msg)\n  File \"/usr/local/lib/python3.5/dist-packages/ipykernel/kernelbase.py\", line 399, in execute_request\n    user_expressions, allow_stdin)\n  File \"/usr/local/lib/python3.5/dist-packages/ipykernel/ipkernel.py\", line 208, in do_execute\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"/usr/local/lib/python3.5/dist-packages/ipykernel/zmqshell.py\", line 537, in run_cell\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n  File \"/usr/local/lib/python3.5/dist-packages/IPython/core/interactiveshell.py\", line 2728, in run_cell\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"/usr/local/lib/python3.5/dist-packages/IPython/core/interactiveshell.py\", line 2856, in run_ast_nodes\n    if self.run_code(code, result):\n  File \"/usr/local/lib/python3.5/dist-packages/IPython/core/interactiveshell.py\", line 2910, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-12-3d7407813c09>\", line 1, in <module>\n    train_on_batch(skill_array,response_array, skill_response_array,custom_loss=True)\n  File \"<ipython-input-8-3bcacaa56c49>\", line 120, in train_on_batch\n    dkt.build_train_on_batch()\n  File \"<ipython-input-6-62915bb7d773>\", line 110, in build_train_on_batch\n    lstm_out = LSTM(self.hidden_layer_size, return_sequences=True)(masked)\n  File \"/usr/local/lib/python3.5/dist-packages/keras/layers/recurrent.py\", line 499, in __call__\n    return super(RNN, self).__call__(inputs, **kwargs)\n  File \"/usr/local/lib/python3.5/dist-packages/keras/engine/topology.py\", line 619, in __call__\n    output = self.call(inputs, **kwargs)\n  File \"/usr/local/lib/python3.5/dist-packages/keras/layers/recurrent.py\", line 2151, in call\n    initial_state=initial_state)\n  File \"/usr/local/lib/python3.5/dist-packages/keras/layers/recurrent.py\", line 608, in call\n    input_length=timesteps)\n  File \"/usr/local/lib/python3.5/dist-packages/keras/backend/tensorflow_backend.py\", line 2593, in rnn\n    inputs = tf.transpose(inputs, (axes))\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/ops/array_ops.py\", line 1476, in transpose\n    ret = transpose_fn(a, perm, name=name)\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/ops/gen_array_ops.py\", line 8215, in transpose\n    \"Transpose\", x=x, perm=perm, name=name)\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/framework/op_def_library.py\", line 787, in _apply_op_helper\n    op_def=op_def)\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/framework/ops.py\", line 3306, in create_op\n    op_def=op_def)\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/framework/ops.py\", line 1669, in __init__\n    self._traceback = self._graph._extract_stack()  # pylint: disable=protected-access\n\nResourceExhaustedError (see above for traceback): OOM when allocating tensor with shape[100,400,963] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc\n\t [[Node: lstm_2/transpose = Transpose[T=DT_FLOAT, Tperm=DT_INT32, _device=\"/job:localhost/replica:0/task:0/device:GPU:0\"](masking_2/mul, lstm_2/transpose/perm)]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\n\n\t [[Node: metrics_1/custom_metric_accuracy/Mean_2/_321 = _Recv[client_terminated=false, recv_device=\"/job:localhost/replica:0/task:0/device:CPU:0\", send_device=\"/job:localhost/replica:0/task:0/device:GPU:0\", send_device_incarnation=1, tensor_name=\"edge_406_metrics_1/custom_metric_accuracy/Mean_2\", tensor_type=DT_FLOAT, _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"]()]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\n\n"
     ]
    }
   ],
   "source": [
    "train_on_batch(skill_array,response_array, skill_response_array,custom_loss=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_on_batch(skill_array,response_array, skill_response_array,custom_loss=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_on_batch(skill_array,response_array, skill_response_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# phase 1 : is_behaviour=FALSE\n",
    "skill_matrix,response_array,problem_num, non_problem_event_num=load_data(skill,response,event_dict,problem_num=336,is_behaviour=False)\n",
    "skill_matrix=skill_matrix[:1000,:]\n",
    "response_array=response_array[:1000,:]\n",
    "print('Number of non-problem events:', non_problem_event_num)\n",
    "skill_array, response_array, skill_response_array=preprocess(skill_matrix,response_array,problem_num, non_problem_event_num)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_on_batch(skill_array,response_array, skill_response_array,custom_loss=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "k=np.array([0,0,0,0,10,15,6,7]).reshape(2,2,2)\n",
    "k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "sess = tf.InteractiveSession()\n",
    "s=(K.argmax(k,axis=-1))\n",
    "s.eval().shape\n",
    "o=tf.one_hot(\n",
    "    s,\n",
    "    4,\n",
    "    on_value=3,\n",
    "    off_value=0,\n",
    "    axis=-1,\n",
    "    dtype=None\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "o.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "K.mean(K.sum(o,axis=-1)).eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "K.sum(o,axis=-1).eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
